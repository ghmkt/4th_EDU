# 제출 시 제목을 Session07 이름으로 해주세요.

# Recommendation Algorithm

# Surprise 내장 영화 데이터(ml-100k)를 로드하여 “UBCF hardcoding.ipynb” 내의 코드를 따라 UBCF를 해주세요.
# 코사인 유사도를 기준으로 KNN 알고리즘을 작성해주세요. (k는 임의로 설정)
# sklearn 모듈 내의 kfold 함수를 이용해 5-fold Cross Validation을 시행하고, Absolute Error의 평균을 최종적으로 출력해주세요.

from collections import defaultdict, Counter; import pandas as pd; import numpy as np
import surprise

from surprise import Dataset
data = surprise.Dataset.load_builtin('ml-100k')
df = pd.DataFrame(data.raw_ratings, columns = ['user', 'item', 'rate', 'id'])

cnt = Counter(df['item']) 
idx_sorted = sorted(list(cnt.keys()), key=lambda x: -cnt[x])

idx = np.zeros(len(df))
for i in idx_sorted[:400]:
    idx += (df['item'] == i) 
idx = np.array(idx, dtype=bool) 

new_df = df[idx].iloc[:,:3]
del df 

def cos_sim(x, y):
    return np.dot(x, y) ** 2 / (np.dot(x, x) * np.dot(y, y))

def find_neighbors(utility_matrix, k, sim_fun): 
    sim_dict = {} 
    cnt = 0 
    for i in utility_matrix.index:
        cnt += 1 
        ranking = [(0,0)] * k
        for j in utility_matrix.index.drop(i): 
            ranking.append((j, sim_fun(utility_matrix.loc[i], utility_matrix.loc[j]))) # (j, simmilarity between i & j) append
            ranking = sorted(ranking, key=lambda x: -x[1])[:k] 
        sim_dict[i] = ranking 
        if not cnt%10: print(cnt) 
    return sim_dict

neighbors = find_neighbors(utility_matrix, 10, cos_sim)

def prediction(item, user, neighbors, utility_matrix): 
    my_neighbors = neighbors[item] 
    rates = []
    for i, _ in my_neighbors:
        r = utility_matrix.loc[i, user] 
        if r > 0: rates.append(r)
    if rates == []: return None
    else: return sum(rates)/len(rates)

def testing(test, neighbors, utility_matrix): # test data에 대해 test하는 함수
    predicted = []
    movies = utility_matrix.columns # train data에 있는 영화 목록
    for i in range(len(test)): # test set에 대해 반복을 돌립니다
        user = test.iloc[i,0]; item = test.iloc[i,1] # 각 row의 movie, user Id를 따옴
        if (item not in neighbors) or (user not in movies): # 만약 해당 user의 neighbor data가 없거나, movie가 train movie 목록에 없다면
            predicted.append(None) # 그 데이터에 관해서는 test를 할 수 없음
        else: predicted.append(prediction(item, user, neighbors, utility_matrix)) # 아니라면 예측을 합니다
    return predicted

from sklearn.model_selection import KFold
cv = KFold(n_splits=5, shuffle=True, random_state=0)
for train_index, test_index in cv.split(new_df):
    train = new_df.iloc[train_index,]
    test = new_df.iloc[test_index,]
    utility_matrix = train.pivot(index='item', columns='user', values='rate').fillna(0) # utility matrix 형태로 바꾸어 줌
    test['prediction'] = testing(test, neighbors, utility_matrix)
    test['diff'] = test['rate'] - test['prediction']
    print("test index:", test_index)
    print("train index:", train_index)
    print(test['diff'].apply(abs).mean())
    
<결과>
test index: [    3    14    17 ... 70444 70448 70450]
train index: [    0     1     2 ... 70447 70449 70451]
0.7648150073410245
test index: [    0     1     6 ... 70429 70447 70451]
train index: [    2     3     4 ... 70448 70449 70450]
0.7534096527483823
test index: [    4     7    15 ... 70443 70445 70446]
train index: [    0     1     2 ... 70449 70450 70451]
0.7546586249823268
test index: [    2     8    12 ... 70438 70440 70449]
train index: [    0     1     3 ... 70448 70450 70451]
0.7507004963260844
test index: [    5    10    13 ... 70435 70436 70439]
train index: [    0     1     2 ... 70449 70450 70451]
0.7490412449893459




# SQL 1

# QUEST 1. quest1 table 이용. 10,000원 이상이거나 재고액이 200,000이상인 제품들의 no, 가격, 재고수량, 재고액을 구해보세요. (열 이름 별칭 사용)
SELECT *, quantity*price AS stock_price FROM quest1 WHERE price > 10000 OR quantity*price > 200000;

# QUEST 2. sample2 table 이용. 사람들의 이름, 나이, 성인 여부를 구해보세요 (열 이름 별칭 사용)
SELECT name,YEAR(CURRENT_TIMESTAMP())-YEAR(birthday)+1 AS age, birthday, CASE WHEN YEAR(birthday) < 2000 THEN 'yes' ELSE 'no' END AS "adult" FROM quest2;
