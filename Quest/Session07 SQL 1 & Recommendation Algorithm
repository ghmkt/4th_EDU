# 제출 시 제목을 Session07 이름으로 해주세요.

# Recommendation Algorithm

# Surprise 내장 영화 데이터(ml-100k)를 로드하여 “UBCF hardcoding.ipynb” 내의 코드를 따라 UBCF를 해주세요.
# 코사인 유사도를 기준으로 KNN 알고리즘을 작성해주세요. (k는 임의로 설정)
# sklearn 모듈 내의 kfold 함수를 이용해 5-fold Cross Validation을 시행하고, Absolute Error의 평균을 최종적으로 출력해주세요.
import pandas as pd
import numpy as np
import surprise
from collections import defaultdict
from collections import defaultdict, Counter
data = surprise.Dataset.load_builtin('ml-100k') # 내장된 영화평 data가 있음
df = pd.DataFrame(data.raw_ratings, columns = ['user', 'item', 'rate', 'id'])
print(df.head())
 cnt = Counter(df['user']) # 각 userId가 몇 번 등장했는지 count한 뒤에
idx_sorted = sorted(list(cnt.keys()), key=lambda x: -cnt[x]) # 빈도가 높은 순서대로 userId를 정렬
idx = np.zeros(len(df)) # df의 전체 row 길이에 해당하는 vector를 만든 뒤에
for i in idx_sorted[:400]:
    idx += (df['user'] == i) # 빈도 400등까지의 userId에 해당하는 row에 1씩을 더해준 뒤,
idx = np.array(idx, dtype=bool) # Boolean 타입으로 바꾸어 줌. -> Bool Indexing을 위한 밑작업
print(idx)
 new_df = df[idx].iloc[:,:3]
del df # 
print(new_df.head())
 from sklearn.model_selection import train_test_split
train, test = train_test_split(new_df, test_size=0.3, random_state=42) # 3:7 비율로 test-train split
 utility_matrix = train.pivot(index='user', columns='item', values='rate').fillna(0) # utility matrix 형태로 바꾸어 줌
# 즉, 각 row의 정보가 각 user의 정보이고, 각 column의 정보가 각 movie에 대한 정보가 되도록
 print(utility_matrix.head()) # 잘 바뀌었군요
 def cos_sim(x, y): # cosine 유사도를 return하는 함수를 define
    return np.dot(x, y) ** 2 / (np.dot(x, x) * np.dot(y, y))
 def cos_sim2(x, y, more_than = 5): # 이것은 겹치는 게 5개 이상인 vector 간에 겹치는 column에 한해 cosine 유사도를 반환하는 함수
    idx = (x>0) & (y>0) # 겹치는 부분만 True이고 나머지는 False인 인덱스 벡터를 만듦
    if sum(idx) < more_than: return 0 # minimum 기준을 충족시키지 못하면 유사도가 없는 것으로 반환
    x_n = x[idx]
    y_n = y[idx]
    return np.dot(x_n, y_n) ** 2 / (np.dot(x_n, x_n) * np.dot(y_n, y_n))
 from scipy.spatial import distance # Euclidean 거리를 구해주는 모듈
 def eucli_sim(x, y, more_than = 5): # 이것은 겹치는 게 5개 이상인 vector 간에 겹치는 column 한정 유클리디언 거리를 반환하는 함수
    idx = (x>0) & (y>0)
    if sum(idx) < more_than: return 100 # 얘는 소소익선이므로, 겹치는 부분이 적으면 크게 반환해주어야 함
    x_n = x[idx]
    y_n = y[idx]
    return distance.euclidean(x_n,y_n)/np.sqrt(len(x_n)) # sqrt(n)으로 나누어주어야 보정이 됨
 def find_neighbors(utility_matrix, k, sim_fun): # 주어진 유사도를 기준으로 k개의 neighbor를 구해보자!
    sim_dict = {} # 각 user들의 이웃들을 내포한 딕셔너리로 만들 것임!
    cnt = 0 # 밑에서 반복문 몇 번 돌았는지 확인하려고...
    for i in utility_matrix.index: # utility_matrix의 index들 = userId들
        cnt += 1 # 반복 1회당 카운트 한 번씩 올려주고
        ranking = [(0,0)] * k
        for j in utility_matrix.index.drop(i): # i를 제외한 나머지 userId에 대해 반복
            ranking.append((j, sim_fun(utility_matrix.loc[i], utility_matrix.loc[j]))) # (j, simmilarity between i & j) append
            ranking = sorted(ranking, key=lambda x: -x[1])[:k] # 각 튜플의 뒤의 원소를 기준으로 내림차순한 뒤(유클리디언은 오름차순 해야됨), k개까지만 cut
        sim_dict[i] = ranking # 위에서 만든 리스트를 sim_dict의 key = i에 대해 append함
        if not cnt%10: print(cnt) # 10단위로 카운트 수를 출력... 얼마나 진행되고 있는지 시각적으로 확인코자 하는 수단
    return sim_dict
 neighbors = find_neighbors(utility_matrix, 10, cos_sim) # 참 느림... cos_sim2나 eucli로 하면 더 느려집니다 ^*^;;
 def prediction(user, item, neighbors, utility_matrix): # 이제 neighbor들의 평균을 냄으로써 평점을 예측해봅시다
    my_neighbors = neighbors[user] # 지정된 user의 이웃들을 꺼낸 뒤
    rates = []
    for i, _ in my_neighbors:
        r = utility_matrix.loc[i, item] # 이웃의 해당 영화에 대한 평점을 꺼내옵니다
        if r > 0: rates.append(r) # 정보가 있을 경우에 리스트에 append
    if rates == []: return None # 만약 리스트가 비어있다면, None을 반환 (왜냐면, 이웃 중에 그 영화를 본 사람이 없는 것이므로)
    else: return sum(rates)/len(rates) # 아니라면 평균을 return합시다
    
def testing(test, neighbors, utility_matrix): # test data에 대해 test하는 함수
    predicted = []
    movies = utility_matrix.columns # train data에 있는 영화 목록
    for i in range(len(test)): # test set에 대해 반복을 돌립니다
        movie = test.iloc[i,0]; user = test.iloc[i,1] # 각 row의 movie, user Id를 따옴
        if (user not in neighbors) or (movie not in movies): # 만약 해당 user의 neighbor data가 없거나, movie가 train movie 목록에 없다면
            predicted.append(None) # 그 데이터에 관해서는 test를 할 수 없음
        else: predicted.append(prediction(user, movie, neighbors, utility_matrix)) # 아니라면 예측을 합니다
    return predicted
 test['prediction'] = testing(test, neighbors, utility_matrix) # 위 함수를 활용한 예측 칼럼을 만듦
test['diff'] = test['rate'] - test['prediction'] # 실제와 예측 간의 차이를 담은 column을 만듦
print(test['diff'].mean())
print(np.sqrt((test['diff'] ** 2).mean()))
 neighbors = find_neighbors(utility_matrix, 10, cos_sim2) # cos_sim2로 테스팅 - %% 속도 느림 주의 %%
test['prediction2'] = testing(test, neighbors, utility_matrix)
test['diff2'] = test['rate'] - test['prediction2']
print(test['diff2'].mean(), np.sqrt((test['diff2'] ** 2).mean())) 
 neighbors = find_neighbors(utility_matrix, 10, cos_sim2) # cos_sim2로 테스팅 - %% 속도 느림 주의 %%
test['prediction2'] = testing(test, neighbors, utility_matrix)
test['diff2'] = test['rate'] - test['prediction2']
print(test['diff2'].mean(), np.sqrt((test['diff2'] ** 2).mean())) 
 print(test['diff'].apply(abs).mean(), test['diff2'].apply(abs).mean(), test['diff3'].apply(abs).mean())
 # 코사인 유사도를 기준으로 KNN 알고리즘을 작성해주세요. (k는 임의로 설정)
# sklearn 모듈 내의 kfold 함수를 이용해 5-fold Cross Validation을 시행하고, Absolute Error의 평균을 최종적으로 출력해주세요.
import sklearn
from sklearn.neighbors import KNeighborsClassifier
 knn = KNeighborsClassifier(n_neighbors=3, metric = "cosine")
 X = new_df[['user', 'item']]
Y = new_df['rate']
 from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error
 cv = KFold(n_splits = 5, shuffle = True, random_state = 0)
for train_index, test_index in cv.split(new_df):
    error = []
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]
    knn.fit(X_train, Y_train)
    test_pred = knn.predict(X_test)
    accuracy= np.mean(np.array(Y_test).astype(np.int32)== test_pred)
    error_value = mean_absolute_error(Y_test, test_pred)
    error = error.append(error_value)
    
    print("test index:", test_index)
    print("train index:", train_index)
    print(error_value)
    
MAE = error.mean()
print(MAE)

# SQL 1

# QUEST 1. quest1 table 이용. 10,000원 이상이거나 재고액이 200,000이상인 제품들의 no, 가격, 재고수량, 재고액을 구해보세요. (열 이름 별칭 사용)
SELECT *, quantity*price AS stock_price FROM quest1 WHERE price >= 10000 OR quantity*price >= 200000;
# QUEST 2. sample2 table 이용. 사람들의 이름, 나이, 성인 여부를 구해보세요 (열 이름 별칭 사용)
SELECT name, year(current_timestamp()) - year(birthday)+1 AS age, CASE WHEN year(birthday) >2000 THEN 'no' ELSE 'yes' END AS 'adult' FROM quest2;
